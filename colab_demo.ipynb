{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Skate Physics Preserver - Pipeline Demo\n",
        "\n",
        "**Human-Object Relational Mapping for V2V Synthesis**\n",
        "\n",
        "This notebook walks through the three-stage pipeline:\n",
        "1. **Extract** - DWPose skeleton + SAM 2.1 object mask\n",
        "2. **Generate** - Headless ComfyUI with Wan 2.1 VACE\n",
        "3. **Validate** - Frame-by-frame IoU (Zero-Clipping Benchmark)\n",
        "\n",
        "Optimized for RTX 3070 8GB VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup & Dependency Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "os.chdir(os.path.dirname(os.path.abspath('__file__')))\n",
        "sys.path.insert(0, 'src')\n",
        "\n",
        "# Verify GPU\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA:    {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    gpu = torch.cuda.get_device_name(0)\n",
        "    vram = torch.cuda.get_device_properties(0).total_mem / (1024**3)\n",
        "    print(f'GPU:     {gpu} ({vram:.1f} GB)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Extract Tracking Data\n",
        "\n",
        "Run DWPose + SAM 2.1 sequentially to extract skeleton poses and object masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "VIDEO_PATH = 'input.mp4'          # Your source video\n",
        "OUTPUT_DIR = 'output'              # Base output directory\n",
        "SAM_CHECKPOINT = 'checkpoints/sam2.1_hiera_small.pt'\n",
        "SAM_CONFIG = 'configs/sam2.1/sam2.1_hiera_s.yaml'\n",
        "\n",
        "# Bounding box around the skateboard in frame 0 [x1, y1, x2, y2]\n",
        "# Set to None for interactive selection\n",
        "SKATEBOARD_BBOX = [120, 340, 280, 410]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "masks_dir = os.path.join(OUTPUT_DIR, 'mask_skateboard')\n",
        "poses_dir = os.path.join(OUTPUT_DIR, 'pose_skater')\n",
        "json_dir  = os.path.join(OUTPUT_DIR, 'pose_json')\n",
        "\n",
        "# --- Pass 1: DWPose ---\n",
        "from tracking.skater_pose import SkaterPoseExtractor\n",
        "\n",
        "pose = SkaterPoseExtractor(device='cuda', mode='balanced')\n",
        "n_pose = pose.process_video(VIDEO_PATH, poses_dir, json_dir)\n",
        "pose.cleanup()\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(f'\\nPose frames: {n_pose}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Pass 2: SAM 2.1 ---\n",
        "from tracking.skateboard_tracker import SkateboardTracker\n",
        "\n",
        "tracker = SkateboardTracker(SAM_CHECKPOINT, SAM_CONFIG, device='cuda')\n",
        "tracker.init_video(VIDEO_PATH)\n",
        "tracker.add_initial_prompt(frame_idx=0, bbox=SKATEBOARD_BBOX)\n",
        "n_mask = tracker.propagate_and_save(masks_dir)\n",
        "tracker.cleanup()\n",
        "print(f'\\nMask frames: {n_mask}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a sample frame\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sample_idx = 0\n",
        "mask = cv2.imread(os.path.join(masks_dir, f'frame_{sample_idx:05d}.png'), 0)\n",
        "pose_img = cv2.imread(os.path.join(poses_dir, f'frame_{sample_idx:05d}.png'))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "axes[0].imshow(mask, cmap='gray')\n",
        "axes[0].set_title('SAM 2.1 Object Mask')\n",
        "axes[1].imshow(cv2.cvtColor(pose_img, cv2.COLOR_BGR2RGB))\n",
        "axes[1].set_title('DWPose Skeleton')\n",
        "for ax in axes: ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Reskin (ComfyUI)\n",
        "\n",
        "Requires a running ComfyUI server: `python main.py --listen --lowvram`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from generate_reskin import ComfyOrchestrator\n",
        "\n",
        "orch = ComfyOrchestrator(server_addr='127.0.0.1:8188')\n",
        "\n",
        "# Check server\n",
        "if orch.check_server():\n",
        "    output_file = orch.execute_v2v(\n",
        "        workflow_path='workflows/vace_template.json',\n",
        "        source_video_path=VIDEO_PATH,\n",
        "        masks_dir=masks_dir,\n",
        "        poses_dir=poses_dir,\n",
        "        positive_prompt='cyberpunk samurai riding a neon hoverboard, cinematic',\n",
        "        negative_prompt='blurry, distorted, low quality, deformed',\n",
        "        output_dir='output/generated',\n",
        "    )\n",
        "    print(f'Output: {output_file}')\n",
        "else:\n",
        "    print('ComfyUI server not running. Start with: python main.py --listen --lowvram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Validate (IoU)\n",
        "\n",
        "Re-track the generated video and compute frame-by-frame IoU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate_iou import load_mask_sequence, extract_generated_masks, run_validation, print_report\n",
        "\n",
        "GENERATED_VIDEO = 'output/generated/output.mp4'  # adjust filename as needed\n",
        "\n",
        "# Load ground truth\n",
        "gt_masks = load_mask_sequence(masks_dir)\n",
        "\n",
        "# Reverse-track generated video\n",
        "gen_masks = extract_generated_masks(\n",
        "    video_path=GENERATED_VIDEO,\n",
        "    bbox=SKATEBOARD_BBOX,\n",
        "    sam_checkpoint=SAM_CHECKPOINT,\n",
        "    sam_config=SAM_CONFIG,\n",
        "    device='cuda',\n",
        ")\n",
        "\n",
        "# Validate\n",
        "results = run_validation(gt_masks, gen_masks, threshold=0.90, verbose=False)\n",
        "print_report(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot IoU over time\n",
        "if results['all_scores']:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(results['all_scores'], 'b-', linewidth=0.8)\n",
        "    plt.axhline(y=0.90, color='r', linestyle='--', label='Threshold (0.90)')\n",
        "    plt.fill_between(range(len(results['all_scores'])), results['all_scores'], 0.90,\n",
        "                     where=[s < 0.90 for s in results['all_scores']],\n",
        "                     color='red', alpha=0.3, label='Failed frames')\n",
        "    plt.xlabel('Frame')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.title('Zero-Clipping Benchmark: IoU Over Time')\n",
        "    plt.legend()\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
